# Question answering datasets

NOTE: PARL.AI does a tremendous job in including different tasks. Thus it would make sense to analyze their state before starting to include more tasks http://www.parl.ai/static/docs/tasks.html# 

This collection includes the following datasets or respectivly looks at the following datasets to be included:

* added: http://www.okbqa.org/nlq
* added: http://greententacle.techfak.uni-bielefeld.de/~cunger/qald/
* added: http://linkedspending.org

in production (adding answers):
* https://www.stonetemple.com/great-knowledge-box-showdown/

Overview articles:
* https://github.com/karthikncode/nlp-datasets
* http://www.cs.cmu.edu/~ark/QA-data/
* http://searchivarius.org/dir/000/00I/000
* https://github.com/sebastianruder/NLP-progress/blob/master/question_answering.md

QA datasets to analyze: 
* WebQuestions Semantic Parses Dataset https://www.microsoft.com/en-us/download/confirmation.aspx?id=52763
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* http://parl.ai/
* www.msmarco.org
* https://github.com/ysu1989/GraphQuestions/tree/master/freebase13
* http://dl.acm.org/citation.cfm?id=2878551
* TriviaQA for 95k reading comprehension questions http://nlp.cs.washington.edu/triviaqa/ 
* convai.io 
* https://github.com/deepmind/aqua Algebraic QA
* https://www.microsoft.com/en-us/download/details.aspx?id=52763
* http://datasets.maluuba.com/NewsQA
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional questions; multiple paraphrases for each question 
* http://qallme.fbk.eu/index.php?location=benchmark
* http://agarciaduran.org/ 30M questions to freebase
* https://github.com/brmson/yodaqa/wiki/Benchmarks
 * https://github.com/brmson/dataset-factoid-curated for evolution 
 * https://github.com/brmson/dataset-factoid-movies for domain-specific
 * https://github.com/brmson/dataset-factoid-webquestions for a suit
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional and paraphrased questions 
* http://www-nlp.stanford.edu/software/sempre/
* http://research.microsoft.com/en-us/um/redmond/projects/mctest/ 
* https://sites.google.com/site/trecliveqa2015/
* http://trec.nist.gov/data/qa.html
* http://trec.nist.gov/data/qamain.html
* http://trec.nist.gov/data/qa/add_qaresources.html
* http://www.slideshare.net/andrenfreitas/schema-agnostic
* http://research.microsoft.com/en-us/downloads/88c0021c-328a-4148-a158-a42d7331c6cf/
* http://projects.semwebcentral.org/ (?)
* http://research.signalmedia.co/newsir16/signal-dataset.html
* Kaggle AI challenge or in general multiple choice questions (e.g., QALD entrance exams)
* needs computation: https://github.com/deepmind/rc-data/
* Federated Queries https://code.google.com/archive/p/fbench/
* http://talc1.loria.fr/webnlg/stories/deliverables.html
* http://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/
* https://cs.umd.edu/~miyyer/qblearn/
* https://ciir.cs.umass.edu/downloads/nfL6/
* https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view
* https://machinelearningmastery.com/datasets-natural-language-processing/
* https://arxiv.org/abs/1805.05942
out of scope (?) :
* http://alt.qcri.org/semeval2015/task3/ SemEval-2015 Task 3: Answer Selection in Community Question Answering 
* http://alt.qcri.org/semeval2016/task3/ Semeval-2016 Task 3: Community Question Answering
* https://www.microsoft.com/en-us/download/details.aspx?id=52419 WikiQA (big!)
* https://stanford-qa.com/ 100k+ questions with leaderboard 
* http://www.aclweb.org/anthology/P/P16/P16-1145.pdf WIKIREADING, largest dataset!
* http://www.cl.ecei.tohoku.ac.jp/rite2/doku.php?id=wiki:resources only japanese
* QGSTEC automatic question generation workshop
* http://www.cs.cmu.edu/~ark/QA-data/ 
* http://webscope.sandbox.yahoo.com/catalog.php?datatype=l
* https://arxiv.org/abs/1710.06481
* http://qangaroo.cs.ucl.ac.uk/
* https://arxiv.org/abs/1805.03797
* http://jmcauley.ucsd.edu/data/amazon/qa/
* http://www.aclweb.org/aclwiki/index.php?title=Question_Answering_(State_of_the_art) 
* https://stackoverflow.blog/2009/06/stack-overflow-creative-commons-data-dump/
* https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2#.51rfdj1kd 
* http://mrc2018.cipsc.org.cn/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=NLP%20News
*   [Identifying key phrases in text](https://www.crowdflower.com/data-for-everyone/): Question/Answer pairs + context; context was judged if relevant to question/answer. (8 MB)
*   [Jeopardy](http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/): archive of 216,930 past Jeopardy questions (53 MB)
*   [MCTest](http://research.microsoft.com/en-us/um/redmond/projects/mctest/index.html): a freely available set of 660 stories and associated questions intended for research on the machine comprehension of text; for question answering (1 MB)
*   [Stackoverflow](http://data.stackexchange.com/): 7.3 million stackoverflow questions + other stackexchanges (query tool)
*   [Yahoo! Answers Comprehensive Questions and Answers](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Yahoo! Answers corpus as of 10/25/2007. Contains 4,483,032 questions and their answers. (3.6 GB)
*   [Yahoo! Answers consisting of questions asked in French](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Subset of the Yahoo! Answers corpus from 2006 to 2015 consisting of 1.7 million questions posed in French, and their corresponding answers. (3.8 GB)
*   [Yahoo! Answers Manner Questions](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): subset of the Yahoo! Answers corpus from a 10/25/2007 dump, selected for their linguistic properties. Contains 142,627 questions and their answers. (104 MB)
* https://sites.google.com/view/qanta/home
* https://transacl.org/ojs/index.php/tacl/article/view/1325
* https://msropendata.com/datasets/d8d67c14-9d3f-4aeb-8178-4b2f8fb46c55
* https://msropendata.com/datasets/939b1042-6402-4697-9c15-7a28de7e1321

## Focus
This collection aims at becoming a central focus point of question answering research. Using deeper analysis (sentiment, clustering, topic) of a questions will help to understand arising difficulties within QA systems. Moreover, this collection will help also semantic search, e.g. keyword search, phrase search, in later stages.

## Maven Dependency
This library is available as snapshot here: http://maven.aksw.org/archiva/#artifact~snapshots/org.aksw.qa/datasets

```
<dependency>
  <groupId>org.aksw.qa</groupId>
  <artifactId>datasets</artifactId>
  <version>0.5.12</version>
</dependency>
```
Add the following repository:
```
<repository>
			<id>maven.aksw.internal</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/internal</url>
		</repository>
		<repository>
			<id>maven.aksw.snapshots</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/snapshots</url>
</repository>
```

Look for more interesting libraries here: http://maven.aksw.org/archiva/#browse/org.aksw.qa 

### Acknowledgement
- Sources: https://raw.githubusercontent.com/niderhoff/nlp-datasets/master/README.md
